{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa99cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3b406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25f050624d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------- Hyperparams -----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_PATH      = \"data\\\\shekspeer.txt\"   # put your domain text here\n",
    "batch_size     = 256\n",
    "context_length = 128\n",
    "embedding_dim  = 256\n",
    "num_layers     = 6\n",
    "num_heads      = 8\n",
    "dropout        = 0.1\n",
    "lr             = 3e-4\n",
    "max_steps      = 20000\n",
    "eval_interval  = 200\n",
    "eval_iters     = 50\n",
    "seed           = 42\n",
    "random.seed(seed); torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2336b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Byte tokenizer -----------------\n",
    "class ByteTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocab_size = 256\n",
    "    def encode(self, s: str): return list(s.encode(\"utf-8\"))\n",
    "    def decode(self, ids):    return bytes(ids).decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "tokenizer = ByteTokenizer()\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# ----------------- Data -----------------\n",
    "def load_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    ids = tokenizer.encode(text)\n",
    "    n = int(0.9 * len(ids))\n",
    "    return ids[:n], ids[n:]\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, data, block):\n",
    "        self.data = data; self.block = block\n",
    "    def __len__(self): return max(1, len(self.data) - self.block)\n",
    "    def __getitem__(self, i):\n",
    "        x = torch.tensor(self.data[i:i+self.block], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[i+1:i+self.block+1], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d5639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Model bits (like your screenshots) -----------------\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key   = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head_size = head_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B, T, H)\n",
    "        q = self.query(x) # (B, T, H)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        wei = q @ k.transpose(-2, -1) / math.sqrt(self.head_size)  # (B, T, T)\n",
    "\n",
    "        # causal mask (no looking ahead)\n",
    "        mask = torch.triu(torch.ones(T, T, device=x.device), diagonal=1).bool()\n",
    "        wei = wei.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        v = self.value(x)             # (B, T, H)\n",
    "        out = wei @ v                 # (B, T, H)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj  = nn.Linear(head_size * num_heads, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)  # (B, T, C)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super().__init__()\n",
    "        head_size = hidden_dim // num_heads\n",
    "        self.attn = MultiHeadAttention(head_size, num_heads)\n",
    "        self.ff   = FeedForward(hidden_dim)\n",
    "        self.ln1  = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2  = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))  # pre-LN + residual\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class SmallLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embedding   = nn.Embedding(context_length, embedding_dim)\n",
    "        self.blocks = nn.Sequential(*[Block(embedding_dim, num_heads) for _ in range(num_layers)])\n",
    "        self.ln = nn.LayerNorm(embedding_dim)\n",
    "        self.lm_head = nn.Linear(embedding_dim, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "\n",
    "        tok_emb = self.token_embedding(x)                          # (B, T, C)\n",
    "        pos_idx = torch.arange(T, device=x.device).unsqueeze(0)    # (1, T)\n",
    "        pos_emb = self.pos_embedding(pos_idx)                      # (1, T, C)\n",
    "        x = tok_emb + pos_emb                                      # (B, T, C)\n",
    "\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.lm_head(x)                                   # (B, T, V)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        return logits, loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model, idx, max_new_tokens=200, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    # idx: (B, T)\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_length:]\n",
    "        logits, _ = model(idx_cond)\n",
    "        logits = logits[:, -1, :] / max(1e-8, temperature)  # (B, V)\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            thresh = v[:, [-1]]\n",
    "            logits = torch.where(logits < thresh, torch.full_like(logits, -1e10), logits)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)          # (B, 1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "    return idx\n",
    "\n",
    "# ----------------- Train -----------------\n",
    "def estimate_loss(model, loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            if i >= eval_iters: break\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, loss = model(x, y)\n",
    "            losses.append(loss.item())\n",
    "    model.train()\n",
    "    return sum(losses) / len(losses) if losses else float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0 | train loss 5.7379\n",
      "*** eval step 0: val loss 5.2327\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "h�`�IES�� Tg�\u001ee\u0006��4o��\u001bg�휸B�Fu^�w^�&���8�#����m?/��\u0019�1u�r\u0016�p���s^�4e�ma���yrp+n��Ie�V��\n",
      "step    20 | train loss 3.0616\n",
      "step    40 | train loss 2.6802\n",
      "step    60 | train loss 2.5637\n",
      "step    80 | train loss 2.4930\n",
      "step   100 | train loss 2.4564\n",
      "step   120 | train loss 2.4223\n",
      "step   140 | train loss 2.4022\n",
      "step   160 | train loss 2.3591\n",
      "step   180 | train loss 2.3305\n",
      "step   200 | train loss 2.2753\n",
      "*** eval step 200: val loss 2.2838\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "Bor ar a oflant anghar ous hof ben, fas.\n",
      "\n",
      "HOLIOLENTINS:\n",
      "Thir, ck, thusthot f yird,\n",
      "Theveru bade hat aly.\n",
      "\n",
      "WISAUS:\n",
      "Harplla\n",
      "step   220 | train loss 2.2463\n",
      "step   240 | train loss 2.2044\n",
      "step   260 | train loss 2.1489\n",
      "step   280 | train loss 2.0987\n",
      "step   300 | train loss 2.0644\n",
      "step   320 | train loss 2.0210\n",
      "step   340 | train loss 1.9991\n",
      "step   360 | train loss 1.9673\n",
      "step   380 | train loss 1.9239\n",
      "step   400 | train loss 1.8799\n",
      "*** eval step 400: val loss 1.9740\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "By not sight make not him.\n",
      "\n",
      "VORYCK:\n",
      "Then hable 'is wis maspalats the stat munce?\n",
      "RAMIV:\n",
      "y bearde pliare rineart nor that \n",
      "step   420 | train loss 1.8630\n",
      "step   440 | train loss 1.8396\n",
      "step   460 | train loss 1.8132\n",
      "step   480 | train loss 1.7894\n",
      "step   500 | train loss 1.7694\n",
      "step   520 | train loss 1.7413\n",
      "step   540 | train loss 1.7135\n",
      "step   560 | train loss 1.7050\n",
      "step   580 | train loss 1.7132\n",
      "step   600 | train loss 1.6792\n",
      "*** eval step 600: val loss 1.7843\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "Be my gone of the with hands unto like,\n",
      "And frever all in the Jurch of stone have thy and\n",
      "And my my should betrage night;\n",
      "step   620 | train loss 1.6718\n",
      "step   640 | train loss 1.6539\n",
      "step   660 | train loss 1.6354\n",
      "step   680 | train loss 1.6139\n",
      "step   700 | train loss 1.6156\n",
      "step   720 | train loss 1.5773\n",
      "step   740 | train loss 1.5810\n",
      "step   760 | train loss 1.5572\n",
      "step   780 | train loss 1.5781\n",
      "step   800 | train loss 1.5361\n",
      "*** eval step 800: val loss 1.6391\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "But not would herreity brainst come in sudestes?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Though semposay,\n",
      "Which comming Richard: raw honess hath\n",
      "step   820 | train loss 1.5407\n",
      "step   840 | train loss 1.5314\n",
      "step   860 | train loss 1.5029\n",
      "step   880 | train loss 1.5101\n",
      "step   900 | train loss 1.4930\n",
      "step   920 | train loss 1.5015\n",
      "step   940 | train loss 1.4973\n",
      "step   960 | train loss 1.4566\n",
      "step   980 | train loss 1.4668\n",
      "step  1000 | train loss 1.4676\n",
      "*** eval step 1000: val loss 1.5422\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "But ant the Montate, what with me hasbear\n",
      "Which you in swext and of blood and by:\n",
      "Say then you well deiness, what a it in\n",
      "step  1020 | train loss 1.4551\n",
      "step  1040 | train loss 1.4291\n",
      "step  1060 | train loss 1.4345\n",
      "step  1080 | train loss 1.4194\n",
      "step  1100 | train loss 1.4342\n",
      "step  1120 | train loss 1.4260\n",
      "step  1140 | train loss 1.4122\n",
      "step  1160 | train loss 1.3995\n",
      "step  1180 | train loss 1.3957\n",
      "step  1200 | train loss 1.3889\n",
      "*** eval step 1200: val loss 1.4950\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "Bornein well be with upon his ead,\n",
      "Insposed he cause a brotches a aide.\n",
      "\n",
      "LEONTES:\n",
      "My lord, Proth, sir, or Stanle Diann is\n",
      "step  1220 | train loss 1.3821\n",
      "step  1240 | train loss 1.3667\n",
      "step  1260 | train loss 1.3652\n",
      "step  1280 | train loss 1.3750\n",
      "step  1300 | train loss 1.3810\n",
      "step  1320 | train loss 1.3596\n",
      "step  1340 | train loss 1.3424\n",
      "step  1360 | train loss 1.3510\n",
      "step  1380 | train loss 1.3567\n",
      "step  1400 | train loss 1.3388\n",
      "*** eval step 1400: val loss 1.4425\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "Be heaven I unto thee, as say the steels,\n",
      "Wish came to our bring shows of men's blood;\n",
      "For content all this but the backs\n",
      "step  1420 | train loss 1.3275\n",
      "step  1440 | train loss 1.3419\n",
      "step  1460 | train loss 1.3218\n",
      "step  1480 | train loss 1.3202\n",
      "step  1500 | train loss 1.3159\n",
      "step  1520 | train loss 1.2988\n",
      "step  1540 | train loss 1.2974\n",
      "step  1560 | train loss 1.2841\n",
      "step  1580 | train loss 1.3006\n",
      "step  1600 | train loss 1.2931\n",
      "*** eval step 1600: val loss 1.4288\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "But what ne'er the surely cheer of their tpells;\n",
      "Or life, O Edward's prove with sons what haste\n",
      "That we have been a breat\n",
      "step  1620 | train loss 1.2749\n",
      "step  1640 | train loss 1.2988\n",
      "step  1660 | train loss 1.2936\n",
      "step  1680 | train loss 1.2644\n",
      "step  1700 | train loss 1.2868\n",
      "step  1720 | train loss 1.2626\n",
      "step  1740 | train loss 1.2682\n",
      "step  1760 | train loss 1.2525\n",
      "step  1780 | train loss 1.2626\n",
      "step  1800 | train loss 1.2529\n",
      "*** eval step 1800: val loss 1.4027\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "But that she hath story our error faults of sounds,\n",
      "Which be stoled two slanders at the vant,\n",
      "He quay hoke clamishd would\n",
      "step  1820 | train loss 1.2590\n",
      "step  1840 | train loss 1.2395\n",
      "step  1860 | train loss 1.2516\n",
      "step  1880 | train loss 1.2294\n",
      "step  1900 | train loss 1.2377\n",
      "step  1920 | train loss 1.2371\n",
      "step  1940 | train loss 1.2246\n",
      "step  1960 | train loss 1.2346\n",
      "step  1980 | train loss 1.1984\n",
      "step  2000 | train loss 1.2079\n",
      "*** eval step 2000: val loss 1.3908\n",
      "saved best_small_lm_like.pt\n",
      "SAMPLE: First Citizen:\n",
      "Bushy, he lay at Bohemia?\n",
      "\n",
      "LUCIO:\n",
      "Not good my good with you will, and that no must\n",
      "for the pilos king shall be fright,\n",
      "I \n",
      "step  2020 | train loss 1.2189\n",
      "step  2040 | train loss 1.2301\n",
      "step  2060 | train loss 1.2177\n",
      "step  2080 | train loss 1.2163\n",
      "step  2100 | train loss 1.2123\n",
      "step  2120 | train loss 1.2009\n",
      "step  2140 | train loss 1.1922\n",
      "step  2160 | train loss 1.1958\n",
      "step  2180 | train loss 1.1875\n",
      "step  2200 | train loss 1.1652\n",
      "*** eval step 2200: val loss 1.3941\n",
      "SAMPLE: First Citizen:\n",
      "But I, sirs, to fight; nor nor Wortun, not measure\n",
      "To speak offence? these fourteen modes, where i' the sacred\n",
      "hath the s\n",
      "step  2220 | train loss 1.1823\n",
      "step  2240 | train loss 1.1716\n",
      "step  2260 | train loss 1.1554\n",
      "step  2280 | train loss 1.1804\n",
      "step  2300 | train loss 1.1631\n",
      "step  2320 | train loss 1.1596\n",
      "step  2340 | train loss 1.1493\n",
      "step  2360 | train loss 1.1626\n",
      "step  2380 | train loss 1.1397\n",
      "step  2400 | train loss 1.1583\n",
      "*** eval step 2400: val loss 1.4089\n",
      "SAMPLE: First Citizen:\n",
      "By marry, the prince of our way.\n",
      "\n",
      "NORTHUCHIO:\n",
      "Stay up, methinks it strange?\n",
      "\n",
      "THOMAS MOWBRAY:\n",
      "Let me keep at my cousin's n\n",
      "step  2420 | train loss 1.1512\n",
      "step  2440 | train loss 1.1364\n",
      "step  2460 | train loss 1.1355\n",
      "step  2480 | train loss 1.1266\n",
      "step  2500 | train loss 1.1378\n",
      "step  2520 | train loss 1.1259\n",
      "step  2540 | train loss 1.1313\n",
      "step  2560 | train loss 1.1246\n",
      "step  2580 | train loss 1.1008\n",
      "step  2600 | train loss 1.1120\n",
      "*** eval step 2600: val loss 1.4135\n",
      "SAMPLE: First Citizen:\n",
      "Bis Let us be preferly in the enemies.\n",
      "Didme the glear that when I rain many have\n",
      "The centradition of his death victory.\n",
      "\n",
      "step  2620 | train loss 1.1115\n",
      "step  2640 | train loss 1.1217\n",
      "step  2660 | train loss 1.0992\n",
      "step  2680 | train loss 1.0853\n",
      "step  2700 | train loss 1.0839\n",
      "step  2720 | train loss 1.0828\n",
      "step  2740 | train loss 1.0722\n",
      "step  2760 | train loss 1.0724\n",
      "step  2780 | train loss 1.0630\n",
      "step  2800 | train loss 1.0747\n",
      "*** eval step 2800: val loss 1.4402\n",
      "SAMPLE: First Citizen:\n",
      "Banished on the severity's presence. Bodientless\n",
      "So much imprison in any morning'd without-tie,\n",
      "To tarch of my grief leav\n",
      "step  2820 | train loss 1.0748\n",
      "step  2840 | train loss 1.0808\n",
      "step  2860 | train loss 1.0621\n",
      "step  2880 | train loss 1.0456\n",
      "step  2900 | train loss 1.0561\n",
      "step  2920 | train loss 1.0486\n",
      "step  2940 | train loss 1.0386\n",
      "step  2960 | train loss 1.0617\n",
      "step  2980 | train loss 1.0444\n",
      "step  3000 | train loss 1.0401\n",
      "*** eval step 3000: val loss 1.4741\n",
      "SAMPLE: First Citizen:\n",
      "Be repeal thee not; the prettiest thou art thyself.\n",
      "\n",
      "BENVOLIO:\n",
      "Siciling those that person from banishment he speed\n",
      "to any\n",
      "step  3020 | train loss 1.0256\n",
      "step  3040 | train loss 1.0239\n",
      "step  3060 | train loss 1.0211\n",
      "step  3080 | train loss 1.0206\n",
      "step  3100 | train loss 1.0050\n",
      "step  3120 | train loss 1.0069\n",
      "step  3140 | train loss 1.0054\n",
      "step  3160 | train loss 0.9887\n",
      "step  3180 | train loss 0.9868\n",
      "step  3200 | train loss 0.9885\n",
      "*** eval step 3200: val loss 1.5214\n",
      "SAMPLE: First Citizen:\n",
      "Break assisting as which, you shames upon this right.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Come, come on, do not so hear elecome home.\n",
      "\n",
      "QUEE\n",
      "step  3220 | train loss 0.9873\n",
      "step  3240 | train loss 0.9817\n",
      "step  3260 | train loss 0.9753\n",
      "step  3280 | train loss 0.9694\n",
      "step  3300 | train loss 0.9669\n",
      "step  3320 | train loss 0.9562\n",
      "step  3340 | train loss 0.9511\n",
      "step  3360 | train loss 0.9583\n",
      "step  3380 | train loss 0.9638\n",
      "step  3400 | train loss 0.9583\n",
      "*** eval step 3400: val loss 1.5662\n",
      "SAMPLE: First Citizen:\n",
      "Be thou may have spent.\n",
      "\n",
      "Messenger:\n",
      "Follow the royal sease that did thee saved me?\n",
      "\n",
      "ELBOW:\n",
      "Come hither, sir; for what he \n",
      "step  3420 | train loss 0.9354\n",
      "step  3440 | train loss 0.9312\n",
      "step  3460 | train loss 0.9141\n",
      "step  3480 | train loss 0.9268\n",
      "step  3500 | train loss 0.9229\n",
      "step  3520 | train loss 0.9155\n",
      "step  3540 | train loss 0.9150\n",
      "step  3560 | train loss 0.8951\n",
      "step  3580 | train loss 0.8971\n",
      "step  3600 | train loss 0.8993\n",
      "*** eval step 3600: val loss 1.6298\n",
      "SAMPLE: First Citizen:\n",
      "But I had write the thought of a deal of is a drum,\n",
      "ship crownes, and coken and odds repose,\n",
      "Stuff they should cannot her\n",
      "step  3620 | train loss 0.8834\n",
      "step  3640 | train loss 0.8820\n",
      "step  3660 | train loss 0.8776\n",
      "step  3680 | train loss 0.8532\n",
      "step  3700 | train loss 0.8708\n",
      "step  3720 | train loss 0.8626\n",
      "step  3740 | train loss 0.8531\n",
      "step  3760 | train loss 0.8625\n",
      "step  3780 | train loss 0.8364\n",
      "step  3800 | train loss 0.8357\n",
      "*** eval step 3800: val loss 1.7068\n",
      "SAMPLE: First Citizen:\n",
      "Bid then girls discrept lay this first to see;\n",
      "And whither follow shield heavy look on.\n",
      "\n",
      "WARWICK:\n",
      "Richmond on all the app\n",
      "step  3820 | train loss 0.8296\n",
      "step  3840 | train loss 0.8283\n",
      "step  3860 | train loss 0.8370\n",
      "step  3880 | train loss 0.8202\n",
      "step  3900 | train loss 0.8113\n",
      "step  3920 | train loss 0.8046\n",
      "step  3940 | train loss 0.7971\n",
      "step  3960 | train loss 0.7847\n",
      "step  3980 | train loss 0.7774\n",
      "step  4000 | train loss 0.7843\n",
      "*** eval step 4000: val loss 1.7914\n",
      "SAMPLE: First Citizen:\n",
      "Bid where he did not plead, bestride the time whipe so?\n",
      "\n",
      "Servant:\n",
      "No, no, no: where's Romeo speak more? I have me not?\n",
      "\n",
      "T\n",
      "step  4020 | train loss 0.7825\n",
      "step  4040 | train loss 0.7823\n",
      "step  4060 | train loss 0.7856\n",
      "step  4080 | train loss 0.7722\n",
      "step  4100 | train loss 0.7599\n",
      "step  4120 | train loss 0.7618\n",
      "step  4140 | train loss 0.7398\n",
      "step  4160 | train loss 0.7455\n",
      "step  4180 | train loss 0.7368\n",
      "step  4200 | train loss 0.7373\n",
      "*** eval step 4200: val loss 1.8952\n",
      "SAMPLE: First Citizen:\n",
      "Born at all the while-gawt unto once curstom'd\n",
      "That now-forbiden country that will revenge\n",
      "And let the end of that see wh\n",
      "step  4220 | train loss 0.7283\n",
      "step  4240 | train loss 0.7203\n",
      "step  4260 | train loss 0.7296\n",
      "step  4280 | train loss 0.7184\n",
      "step  4300 | train loss 0.7038\n",
      "step  4320 | train loss 0.7016\n",
      "step  4340 | train loss 0.6865\n",
      "step  4360 | train loss 0.6839\n",
      "step  4380 | train loss 0.6935\n",
      "step  4400 | train loss 0.6690\n",
      "*** eval step 4400: val loss 1.9882\n",
      "SAMPLE: First Citizen:\n",
      "But all in extremity of your company.\n",
      "\n",
      "First Murderer:\n",
      "Why, father; if any brows upon him.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "On Thursday, \n",
      "step  4420 | train loss 0.6814\n",
      "step  4440 | train loss 0.6738\n",
      "step  4460 | train loss 0.6621\n",
      "step  4480 | train loss 0.6669\n",
      "step  4500 | train loss 0.6558\n",
      "step  4520 | train loss 0.6471\n",
      "step  4540 | train loss 0.6430\n",
      "step  4560 | train loss 0.6433\n",
      "step  4580 | train loss 0.6312\n",
      "step  4600 | train loss 0.6275\n",
      "*** eval step 4600: val loss 2.1128\n",
      "SAMPLE: First Citizen:\n",
      "Be he comes. Angry, and knock me well; I wot.\n",
      "A hurager entreaties a second so many mood\n",
      "leits, I would have weigh your w\n",
      "step  4620 | train loss 0.6324\n",
      "step  4640 | train loss 0.6228\n",
      "step  4660 | train loss 0.6234\n",
      "step  4680 | train loss 0.6065\n",
      "step  4700 | train loss 0.6063\n",
      "step  4720 | train loss 0.5971\n",
      "step  4740 | train loss 0.6063\n",
      "step  4760 | train loss 0.5908\n",
      "step  4780 | train loss 0.6003\n",
      "step  4800 | train loss 0.5850\n",
      "*** eval step 4800: val loss 2.2136\n",
      "SAMPLE: First Citizen:\n",
      "Be insinuate, she seeing pursues; which now it home to\n",
      "The justice of his son and nothing here alived\n",
      "Than the castle con\n",
      "step  4820 | train loss 0.5823\n",
      "step  4840 | train loss 0.5788\n",
      "step  4860 | train loss 0.5750\n",
      "step  4880 | train loss 0.5697\n",
      "step  4900 | train loss 0.5772\n",
      "step  4920 | train loss 0.5577\n",
      "step  4940 | train loss 0.5576\n",
      "step  4960 | train loss 0.5408\n",
      "step  4980 | train loss 0.5618\n",
      "step  5000 | train loss 0.5443\n",
      "*** eval step 5000: val loss 2.3614\n",
      "SAMPLE: First Citizen:\n",
      "Be in pardon, for my soul to chide and hear\n",
      "The thought of all, and not the ear.\n",
      "\n",
      "First Gentleman:\n",
      "We are all frail. He w\n",
      "step  5020 | train loss 0.5372\n",
      "step  5040 | train loss 0.5369\n",
      "step  5060 | train loss 0.5334\n",
      "step  5080 | train loss 0.5265\n",
      "step  5100 | train loss 0.5175\n",
      "step  5120 | train loss 0.5196\n",
      "step  5140 | train loss 0.5149\n",
      "step  5160 | train loss 0.5084\n",
      "step  5180 | train loss 0.5006\n",
      "step  5200 | train loss 0.5106\n",
      "*** eval step 5200: val loss 2.4677\n",
      "SAMPLE: First Citizen:\n",
      "Be insolence pound of swords and rich cries not help!\n",
      "\n",
      "BHOP OF ELY:\n",
      "\n",
      "Grood EdwARD:\n",
      "Say, her of the king my brother's daug\n",
      "step  5220 | train loss 0.4869\n",
      "step  5240 | train loss 0.4930\n",
      "step  5260 | train loss 0.4762\n",
      "step  5280 | train loss 0.4859\n",
      "step  5300 | train loss 0.4906\n",
      "step  5320 | train loss 0.4892\n",
      "step  5340 | train loss 0.4753\n",
      "step  5360 | train loss 0.4689\n",
      "step  5380 | train loss 0.4703\n",
      "step  5400 | train loss 0.4627\n",
      "*** eval step 5400: val loss 2.5981\n",
      "SAMPLE: First Citizen:\n",
      "Be in the dove-contempted we will piece of England\n",
      "With Clionment's ripent on his king:\n",
      "The day is hot, the easterness, w\n",
      "step  5420 | train loss 0.4701\n",
      "step  5440 | train loss 0.4744\n",
      "step  5460 | train loss 0.4546\n",
      "step  5480 | train loss 0.4488\n",
      "step  5500 | train loss 0.4520\n",
      "step  5520 | train loss 0.4464\n",
      "step  5540 | train loss 0.4378\n",
      "step  5560 | train loss 0.4409\n",
      "step  5580 | train loss 0.4388\n",
      "step  5600 | train loss 0.4324\n",
      "*** eval step 5600: val loss 2.7412\n",
      "SAMPLE: First Citizen:\n",
      "By something safety through such a story finger,\n",
      "Hast thou that a devil'd sweet report on!\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "That thou dos\n",
      "step  5620 | train loss 0.4333\n",
      "step  5640 | train loss 0.4307\n",
      "step  5660 | train loss 0.4352\n",
      "step  5680 | train loss 0.4221\n",
      "step  5700 | train loss 0.4212\n",
      "step  5720 | train loss 0.4181\n",
      "step  5740 | train loss 0.4260\n",
      "step  5760 | train loss 0.4221\n",
      "step  5780 | train loss 0.4195\n",
      "step  5800 | train loss 0.4081\n",
      "*** eval step 5800: val loss 2.8588\n",
      "SAMPLE: First Citizen:\n",
      "By my head age by this And, by my fair promise; no, hearing my\n",
      "petitions not sither.\n",
      "\n",
      "TRANIO:\n",
      "I pray you, bait from you, \n",
      "step  5820 | train loss 0.4101\n",
      "step  5840 | train loss 0.3987\n",
      "step  5860 | train loss 0.3949\n",
      "step  5880 | train loss 0.3959\n",
      "step  5900 | train loss 0.4017\n",
      "step  5920 | train loss 0.3911\n",
      "step  5940 | train loss 0.3989\n",
      "step  5960 | train loss 0.3867\n",
      "step  5980 | train loss 0.3879\n",
      "step  6000 | train loss 0.3920\n",
      "*** eval step 6000: val loss 2.9805\n",
      "SAMPLE: First Citizen:\n",
      "Be in the boy, sir, I cam ouns.\n",
      "\n",
      "Volsce:\n",
      "Hark! terries one to Claudio is purposed to the\n",
      "ship justice; and in those chang\n",
      "step  6020 | train loss 0.3803\n",
      "step  6040 | train loss 0.3891\n",
      "step  6060 | train loss 0.3816\n",
      "step  6080 | train loss 0.3709\n",
      "step  6100 | train loss 0.3719\n",
      "step  6120 | train loss 0.3767\n",
      "step  6140 | train loss 0.3635\n",
      "step  6160 | train loss 0.3715\n",
      "step  6180 | train loss 0.3642\n",
      "step  6200 | train loss 0.3641\n",
      "*** eval step 6200: val loss 3.0883\n",
      "SAMPLE: First Citizen:\n",
      "Beleed as we hear: in the chase, the one my duke bold,\n",
      "Whom we have hearts them not. O holy seals;\n",
      "For howb I was done my\n",
      "step  6220 | train loss 0.3576\n",
      "step  6240 | train loss 0.3577\n",
      "step  6260 | train loss 0.3607\n",
      "step  6280 | train loss 0.3578\n",
      "step  6300 | train loss 0.3589\n",
      "step  6320 | train loss 0.3562\n",
      "step  6340 | train loss 0.3510\n",
      "step  6360 | train loss 0.3500\n",
      "step  6380 | train loss 0.3458\n",
      "step  6400 | train loss 0.3451\n",
      "*** eval step 6400: val loss 3.2339\n",
      "SAMPLE: First Citizen:\n",
      "Bid the time is come; his will for a man\n",
      "To danger that his countenance.\n",
      "\n",
      "MENENIUS:\n",
      "Well, go, sir.\n",
      "\n",
      "First Senator:\n",
      "From w\n",
      "step  6420 | train loss 0.3426\n",
      "step  6440 | train loss 0.3448\n",
      "step  6460 | train loss 0.3371\n",
      "step  6480 | train loss 0.3265\n",
      "step  6500 | train loss 0.3336\n",
      "step  6520 | train loss 0.3396\n",
      "step  6540 | train loss 0.3313\n",
      "step  6560 | train loss 0.3311\n",
      "step  6580 | train loss 0.3277\n",
      "step  6600 | train loss 0.3232\n",
      "*** eval step 6600: val loss 3.3304\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r lady; seldom comes the better:\n",
      "How woful wondy can bow his standing royalty,\n",
      "The present, that manst be he\n",
      "step  6620 | train loss 0.3239\n",
      "step  6640 | train loss 0.3304\n",
      "step  6660 | train loss 0.3299\n",
      "step  6680 | train loss 0.3145\n",
      "step  6700 | train loss 0.3159\n",
      "step  6720 | train loss 0.3207\n",
      "step  6740 | train loss 0.3165\n",
      "step  6760 | train loss 0.3153\n",
      "step  6780 | train loss 0.3208\n",
      "step  6800 | train loss 0.3133\n",
      "*** eval step 6800: val loss 3.4411\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they all came by the world in a bow.\n",
      "\n",
      "MERCUTIO:\n",
      "A like an unsever'd friends or brown souls upon thee,\n",
      "Down\n",
      "step  6820 | train loss 0.3194\n",
      "step  6840 | train loss 0.3131\n",
      "step  6860 | train loss 0.3127\n",
      "step  6880 | train loss 0.3105\n",
      "step  6900 | train loss 0.3040\n",
      "step  6920 | train loss 0.3025\n",
      "step  6940 | train loss 0.3048\n",
      "step  6960 | train loss 0.3066\n",
      "step  6980 | train loss 0.3102\n",
      "step  7000 | train loss 0.3040\n",
      "*** eval step 7000: val loss 3.5382\n",
      "SAMPLE: First Citizen:\n",
      "Be you content of some pieces of that blood\n",
      "Which here you ready for it.\n",
      "\n",
      "CORIOLANUS:\n",
      "Should there from the mistress! Wha\n",
      "step  7020 | train loss 0.3035\n",
      "step  7040 | train loss 0.3041\n",
      "step  7060 | train loss 0.3024\n",
      "step  7080 | train loss 0.3041\n",
      "step  7100 | train loss 0.3008\n",
      "step  7120 | train loss 0.2870\n",
      "step  7140 | train loss 0.2991\n",
      "step  7160 | train loss 0.2988\n",
      "step  7180 | train loss 0.2921\n",
      "step  7200 | train loss 0.2951\n",
      "*** eval step 7200: val loss 3.5927\n",
      "SAMPLE: First Citizen:\n",
      "Both Tribunes, you shall resour of a gunt\n",
      "Upon then a knight--\n",
      "But as you do,--God give me his just,\n",
      "Till the king stands\n",
      "step  7220 | train loss 0.2925\n",
      "step  7240 | train loss 0.2989\n",
      "step  7260 | train loss 0.2941\n",
      "step  7280 | train loss 0.2902\n",
      "step  7300 | train loss 0.2903\n",
      "step  7320 | train loss 0.2932\n",
      "step  7340 | train loss 0.2911\n",
      "step  7360 | train loss 0.2841\n",
      "step  7380 | train loss 0.2828\n",
      "step  7400 | train loss 0.2856\n",
      "*** eval step 7400: val loss 3.7035\n",
      "SAMPLE: First Citizen:\n",
      "Bad night my soul to hear it.\n",
      "\n",
      "CORIOLANUS:\n",
      "You shall never receive then you\n",
      "Deserve to her accursed crowns of wither'd ha\n",
      "step  7420 | train loss 0.2833\n",
      "step  7440 | train loss 0.2776\n",
      "step  7460 | train loss 0.2752\n",
      "step  7480 | train loss 0.2859\n",
      "step  7500 | train loss 0.2730\n",
      "step  7520 | train loss 0.2761\n",
      "step  7540 | train loss 0.2719\n",
      "step  7560 | train loss 0.2777\n",
      "step  7580 | train loss 0.2726\n",
      "step  7600 | train loss 0.2851\n",
      "*** eval step 7600: val loss 3.7525\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they false, and beat him back again.\n",
      "\n",
      "KING RICHARD II:\n",
      "Hoyday, a devil!\n",
      "Courage, mourself! madam! say, let\n",
      "step  7620 | train loss 0.2761\n",
      "step  7640 | train loss 0.2718\n",
      "step  7660 | train loss 0.2715\n",
      "step  7680 | train loss 0.2689\n",
      "step  7700 | train loss 0.2764\n",
      "step  7720 | train loss 0.2690\n",
      "step  7740 | train loss 0.2739\n",
      "step  7760 | train loss 0.2696\n",
      "step  7780 | train loss 0.2729\n",
      "step  7800 | train loss 0.2667\n",
      "*** eval step 7800: val loss 3.8167\n",
      "SAMPLE: First Citizen:\n",
      "By myself, or o, of the day and 'em!'\n",
      "The cusures the right have forgot that tell thee this short\n",
      "Thou hadst but preposse\n",
      "step  7820 | train loss 0.2685\n",
      "step  7840 | train loss 0.2582\n",
      "step  7860 | train loss 0.2644\n",
      "step  7880 | train loss 0.2708\n",
      "step  7900 | train loss 0.2652\n",
      "step  7920 | train loss 0.2551\n",
      "step  7940 | train loss 0.2694\n",
      "step  7960 | train loss 0.2569\n",
      "step  7980 | train loss 0.2570\n",
      "step  8000 | train loss 0.2572\n",
      "*** eval step 8000: val loss 3.8997\n",
      "SAMPLE: First Citizen:\n",
      "Before the people is as like that Richmond withat tradh,\n",
      "The sedies of justice\n",
      "Madams: the other doth behelme it, and the\n",
      "step  8020 | train loss 0.2577\n",
      "step  8040 | train loss 0.2578\n",
      "step  8060 | train loss 0.2574\n",
      "step  8080 | train loss 0.2525\n",
      "step  8100 | train loss 0.2568\n",
      "step  8120 | train loss 0.2573\n",
      "step  8140 | train loss 0.2535\n",
      "step  8160 | train loss 0.2553\n",
      "step  8180 | train loss 0.2515\n",
      "step  8200 | train loss 0.2506\n",
      "*** eval step 8200: val loss 3.9516\n",
      "SAMPLE: First Citizen:\n",
      "Better it some odds, and as the sufficians they\n",
      "Are reconciled earsed: if any weigh it off wit.\n",
      "\n",
      "AUFIDIUS:\n",
      "Only their end\n",
      "step  8220 | train loss 0.2595\n",
      "step  8240 | train loss 0.2604\n",
      "step  8260 | train loss 0.2469\n",
      "step  8280 | train loss 0.2502\n",
      "step  8300 | train loss 0.2507\n",
      "step  8320 | train loss 0.2514\n",
      "step  8340 | train loss 0.2575\n",
      "step  8360 | train loss 0.2450\n",
      "step  8380 | train loss 0.2463\n",
      "step  8400 | train loss 0.2447\n",
      "*** eval step 8400: val loss 4.0266\n",
      "SAMPLE: First Citizen:\n",
      "Bad night.\n",
      "\n",
      "Third Roman:\n",
      "Be in name till the king was not to be baited\n",
      "With one that wants her wits?\n",
      "\n",
      "LUCENTIO:\n",
      "Truly, Go\n",
      "step  8420 | train loss 0.2503\n",
      "step  8440 | train loss 0.2501\n",
      "step  8460 | train loss 0.2408\n",
      "step  8480 | train loss 0.2444\n",
      "step  8500 | train loss 0.2409\n",
      "step  8520 | train loss 0.2446\n",
      "step  8540 | train loss 0.2455\n",
      "step  8560 | train loss 0.2486\n",
      "step  8580 | train loss 0.2492\n",
      "step  8600 | train loss 0.2504\n",
      "*** eval step 8600: val loss 4.0836\n",
      "SAMPLE: First Citizen:\n",
      "Before the times that would good not, not with the\n",
      "shepherd's bar, years, and privy.\n",
      "\n",
      "ANGELO:\n",
      "I think no less I sin to mu\n",
      "step  8620 | train loss 0.2390\n",
      "step  8640 | train loss 0.2452\n",
      "step  8660 | train loss 0.2404\n",
      "step  8680 | train loss 0.2487\n",
      "step  8700 | train loss 0.2431\n",
      "step  8720 | train loss 0.2385\n",
      "step  8740 | train loss 0.2472\n",
      "step  8760 | train loss 0.2380\n",
      "step  8780 | train loss 0.2369\n",
      "step  8800 | train loss 0.2407\n",
      "*** eval step 8800: val loss 4.1196\n",
      "SAMPLE: First Citizen:\n",
      "Bid them you,\n",
      "You should not be king, put unto our revenge,\n",
      "Who is the fairies may behold while here we lose,\n",
      "That small \n",
      "step  8820 | train loss 0.2385\n",
      "step  8840 | train loss 0.2353\n",
      "step  8860 | train loss 0.2430\n",
      "step  8880 | train loss 0.2378\n",
      "step  8900 | train loss 0.2385\n",
      "step  8920 | train loss 0.2398\n",
      "step  8940 | train loss 0.2413\n",
      "step  8960 | train loss 0.2386\n",
      "step  8980 | train loss 0.2435\n",
      "step  9000 | train loss 0.2397\n",
      "*** eval step 9000: val loss 4.1718\n",
      "SAMPLE: First Citizen:\n",
      "Bad night; lets her go by some be silch,\n",
      "Let me craft truth and made again affords.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Beseech you, sir, h\n",
      "step  9020 | train loss 0.2370\n",
      "step  9040 | train loss 0.2365\n",
      "step  9060 | train loss 0.2401\n",
      "step  9080 | train loss 0.2322\n",
      "step  9100 | train loss 0.2370\n",
      "step  9120 | train loss 0.2311\n",
      "step  9140 | train loss 0.2333\n",
      "step  9160 | train loss 0.2257\n",
      "step  9180 | train loss 0.2348\n",
      "step  9200 | train loss 0.2306\n",
      "*** eval step 9200: val loss 4.2739\n",
      "SAMPLE: First Citizen:\n",
      "Bad ne'er dead, my welcome.\n",
      "\n",
      "BRUTUS:\n",
      "Stay, for the nupe?\n",
      "\n",
      "Messenger:\n",
      "A mile thereof comes closely to die:\n",
      "The duke will d\n",
      "step  9220 | train loss 0.2376\n",
      "step  9240 | train loss 0.2308\n",
      "step  9260 | train loss 0.2369\n",
      "step  9280 | train loss 0.2332\n",
      "step  9300 | train loss 0.2330\n",
      "step  9320 | train loss 0.2213\n",
      "step  9340 | train loss 0.2362\n",
      "step  9360 | train loss 0.2308\n",
      "step  9380 | train loss 0.2366\n",
      "step  9400 | train loss 0.2285\n",
      "*** eval step 9400: val loss 4.2808\n",
      "SAMPLE: First Citizen:\n",
      "Bid the time of lattery for the costains.\n",
      "\n",
      "CORIOLANUS:\n",
      "What means the traught on thing, made me give out a word.\n",
      "\n",
      "ARCHIDA\n",
      "step  9420 | train loss 0.2304\n",
      "step  9440 | train loss 0.2272\n",
      "step  9460 | train loss 0.2349\n",
      "step  9480 | train loss 0.2355\n",
      "step  9500 | train loss 0.2295\n",
      "step  9520 | train loss 0.2284\n",
      "step  9540 | train loss 0.2323\n",
      "step  9560 | train loss 0.2283\n",
      "step  9580 | train loss 0.2282\n",
      "step  9600 | train loss 0.2269\n",
      "*** eval step 9600: val loss 4.3153\n",
      "SAMPLE: First Citizen:\n",
      "Both and howliday.\n",
      "\n",
      "Clown:\n",
      "I had rather have a thousand crowns so nickle\n",
      "Than one cutshiving him, ah with a lord.\n",
      "\n",
      "DORCAS\n",
      "step  9620 | train loss 0.2280\n",
      "step  9640 | train loss 0.2271\n",
      "step  9660 | train loss 0.2267\n",
      "step  9680 | train loss 0.2319\n",
      "step  9700 | train loss 0.2291\n",
      "step  9720 | train loss 0.2181\n",
      "step  9740 | train loss 0.2297\n",
      "step  9760 | train loss 0.2290\n",
      "step  9780 | train loss 0.2233\n",
      "step  9800 | train loss 0.2237\n",
      "*** eval step 9800: val loss 4.3555\n",
      "SAMPLE: First Citizen:\n",
      "Bad news to bown another man, but heaven with you.\n",
      "\n",
      "SICINIUS:\n",
      "We should take it: down to my soul: and I\n",
      "'Tis not thing to\n",
      "step  9820 | train loss 0.2274\n",
      "step  9840 | train loss 0.2266\n",
      "step  9860 | train loss 0.2208\n",
      "step  9880 | train loss 0.2307\n",
      "step  9900 | train loss 0.2262\n",
      "step  9920 | train loss 0.2256\n",
      "step  9940 | train loss 0.2195\n",
      "step  9960 | train loss 0.2200\n",
      "step  9980 | train loss 0.2299\n",
      "step 10000 | train loss 0.2206\n",
      "*** eval step 10000: val loss 4.3749\n",
      "SAMPLE: First Citizen:\n",
      "Because the king is dead; we are King Edward,\n",
      "Vaughan, aboard; there the villain so and\n",
      "the absent duke. Firthwned and ze\n",
      "step 10020 | train loss 0.2200\n",
      "step 10040 | train loss 0.2189\n",
      "step 10060 | train loss 0.2208\n",
      "step 10080 | train loss 0.2213\n",
      "step 10100 | train loss 0.2223\n",
      "step 10120 | train loss 0.2224\n",
      "step 10140 | train loss 0.2219\n",
      "step 10160 | train loss 0.2216\n",
      "step 10180 | train loss 0.2193\n",
      "step 10200 | train loss 0.2175\n",
      "*** eval step 10200: val loss 4.4590\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they all came by the father,\n",
      "Or by the father there were none at all;\n",
      "For I have heard it said on slakes t\n",
      "step 10220 | train loss 0.2156\n",
      "step 10240 | train loss 0.2159\n",
      "step 10260 | train loss 0.2127\n",
      "step 10280 | train loss 0.2189\n",
      "step 10300 | train loss 0.2144\n",
      "step 10320 | train loss 0.2195\n",
      "step 10340 | train loss 0.2148\n",
      "step 10360 | train loss 0.2120\n",
      "step 10380 | train loss 0.2198\n",
      "step 10400 | train loss 0.2203\n",
      "*** eval step 10400: val loss 4.4478\n",
      "SAMPLE: First Citizen:\n",
      "Bad night.\n",
      "\n",
      "ROMEO:\n",
      "You have ta'en a man? that hangs of that that bottled should but\n",
      "Our present did my banishment\n",
      "In the \n",
      "step 10420 | train loss 0.2141\n",
      "step 10440 | train loss 0.2134\n",
      "step 10460 | train loss 0.2158\n",
      "step 10480 | train loss 0.2200\n",
      "step 10500 | train loss 0.2166\n",
      "step 10520 | train loss 0.2092\n",
      "step 10540 | train loss 0.2160\n",
      "step 10560 | train loss 0.2163\n",
      "step 10580 | train loss 0.2212\n",
      "step 10600 | train loss 0.2163\n",
      "*** eval step 10600: val loss 4.4891\n",
      "SAMPLE: First Citizen:\n",
      "By sair the queen's of encounter,\n",
      "but that the queen in hazard of the statue,\n",
      "Should quote your trial which you pronoud\n",
      "S\n",
      "step 10620 | train loss 0.2080\n",
      "step 10640 | train loss 0.2177\n",
      "step 10660 | train loss 0.2181\n",
      "step 10680 | train loss 0.2163\n",
      "step 10700 | train loss 0.2118\n",
      "step 10720 | train loss 0.2138\n",
      "step 10740 | train loss 0.2153\n",
      "step 10760 | train loss 0.2117\n",
      "step 10780 | train loss 0.2169\n",
      "step 10800 | train loss 0.2133\n",
      "*** eval step 10800: val loss 4.5037\n",
      "SAMPLE: First Citizen:\n",
      "Before the time of chancestilate, and\n",
      "curiousted but wpeep, most put unto the deed?\n",
      "Aulthough the will comms.\n",
      "\n",
      "First Citi\n",
      "step 10820 | train loss 0.2109\n",
      "step 10840 | train loss 0.2157\n",
      "step 10860 | train loss 0.2087\n",
      "step 10880 | train loss 0.2123\n",
      "step 10900 | train loss 0.2067\n",
      "step 10920 | train loss 0.2092\n",
      "step 10940 | train loss 0.2137\n",
      "step 10960 | train loss 0.2142\n",
      "step 10980 | train loss 0.2110\n",
      "step 11000 | train loss 0.2136\n",
      "*** eval step 11000: val loss 4.5075\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instint and discourse,\n",
      "Whereof the infant, stain'd by violence,\n",
      "U\n",
      "step 11020 | train loss 0.2100\n",
      "step 11040 | train loss 0.2121\n",
      "step 11060 | train loss 0.2092\n",
      "step 11080 | train loss 0.2120\n",
      "step 11100 | train loss 0.2039\n",
      "step 11120 | train loss 0.2136\n",
      "step 11140 | train loss 0.2104\n",
      "step 11160 | train loss 0.2082\n",
      "step 11180 | train loss 0.2188\n",
      "step 11200 | train loss 0.2059\n",
      "*** eval step 11200: val loss 4.5550\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they all came by the father worse:\n",
      "My babes I may be content, and be a created\n",
      "Which his nature broke said\n",
      "step 11220 | train loss 0.2066\n",
      "step 11240 | train loss 0.2090\n",
      "step 11260 | train loss 0.2050\n",
      "step 11280 | train loss 0.2082\n",
      "step 11300 | train loss 0.2126\n",
      "step 11320 | train loss 0.2092\n",
      "step 11340 | train loss 0.2066\n",
      "step 11360 | train loss 0.2053\n",
      "step 11380 | train loss 0.2120\n",
      "step 11400 | train loss 0.2066\n",
      "*** eval step 11400: val loss 4.5923\n",
      "SAMPLE: First Citizen:\n",
      "Bold Mercutio's cross!\n",
      "\n",
      "ARCILLIUS:\n",
      "They are devised, by the glories,\n",
      "There is any creature of their place.\n",
      "\n",
      "LUCIO:\n",
      "A vill\n",
      "step 11420 | train loss 0.2071\n",
      "step 11440 | train loss 0.2096\n",
      "step 11460 | train loss 0.2033\n",
      "step 11480 | train loss 0.1995\n",
      "step 11500 | train loss 0.2025\n",
      "step 11520 | train loss 0.2006\n",
      "step 11540 | train loss 0.2084\n",
      "step 11560 | train loss 0.2024\n",
      "step 11580 | train loss 0.2029\n",
      "step 11600 | train loss 0.2042\n",
      "*** eval step 11600: val loss 4.6302\n",
      "SAMPLE: First Citizen:\n",
      "By such is the head of all too late.\n",
      "\n",
      "Second Gentleman:\n",
      "'Thou shalt not steal'? why, no; I shall tender will.\n",
      "\n",
      "MENENIUS:\n",
      "\n",
      "step 11620 | train loss 0.1983\n",
      "step 11640 | train loss 0.2058\n",
      "step 11660 | train loss 0.2060\n",
      "step 11680 | train loss 0.2017\n",
      "step 11700 | train loss 0.2037\n",
      "step 11720 | train loss 0.2064\n",
      "step 11740 | train loss 0.2086\n",
      "step 11760 | train loss 0.2028\n",
      "step 11780 | train loss 0.2028\n",
      "step 11800 | train loss 0.2014\n",
      "*** eval step 11800: val loss 4.6534\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of countedable,--\n",
      "\n",
      "AUFIDIUS:\n",
      "My lords, when she devils and virtue little:\n",
      "I take my leave before I have \n",
      "step 11820 | train loss 0.1993\n",
      "step 11840 | train loss 0.1972\n",
      "step 11860 | train loss 0.2037\n",
      "step 11880 | train loss 0.2055\n",
      "step 11900 | train loss 0.1983\n",
      "step 11920 | train loss 0.2023\n",
      "step 11940 | train loss 0.1971\n",
      "step 11960 | train loss 0.1976\n",
      "step 11980 | train loss 0.1970\n",
      "step 12000 | train loss 0.1980\n",
      "*** eval step 12000: val loss 4.7329\n",
      "SAMPLE: First Citizen:\n",
      "Bad hear me speak all in love--\n",
      "\n",
      "MARCIUS:\n",
      "All thou hast made my knees\n",
      "A Mercution like one are consul'd night,\n",
      "Return pla\n",
      "step 12020 | train loss 0.1961\n",
      "step 12040 | train loss 0.1936\n",
      "step 12060 | train loss 0.1987\n",
      "step 12080 | train loss 0.1977\n",
      "step 12100 | train loss 0.1972\n",
      "step 12120 | train loss 0.1967\n",
      "step 12140 | train loss 0.1977\n",
      "step 12160 | train loss 0.2058\n",
      "step 12180 | train loss 0.1954\n",
      "step 12200 | train loss 0.2022\n",
      "*** eval step 12200: val loss 4.6855\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they all came by the father, for\n",
      "Would I were sleepen much designs.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Thou hadst a soldier'\n",
      "step 12220 | train loss 0.1948\n",
      "step 12240 | train loss 0.1953\n",
      "step 12260 | train loss 0.1949\n",
      "step 12280 | train loss 0.1952\n",
      "step 12300 | train loss 0.1971\n",
      "step 12320 | train loss 0.2015\n",
      "step 12340 | train loss 0.1979\n",
      "step 12360 | train loss 0.2014\n",
      "step 12380 | train loss 0.1960\n",
      "step 12400 | train loss 0.1972\n",
      "*** eval step 12400: val loss 4.8007\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instinct men's minds mistrust\n",
      "Ensuing dangers; as by proof, we se\n",
      "step 12420 | train loss 0.1956\n",
      "step 12440 | train loss 0.1961\n",
      "step 12460 | train loss 0.1945\n",
      "step 12480 | train loss 0.2018\n",
      "step 12500 | train loss 0.1975\n",
      "step 12520 | train loss 0.1978\n",
      "step 12540 | train loss 0.1983\n",
      "step 12560 | train loss 0.1897\n",
      "step 12580 | train loss 0.1952\n",
      "step 12600 | train loss 0.1933\n",
      "*** eval step 12600: val loss 4.7988\n",
      "SAMPLE: First Citizen:\n",
      "Bad me you talk of, proudlycury, and you say your daughter:\n",
      "my condpang will no get but for some other\n",
      "statablive, I will\n",
      "step 12620 | train loss 0.1920\n",
      "step 12640 | train loss 0.1907\n",
      "step 12660 | train loss 0.1933\n",
      "step 12680 | train loss 0.1895\n",
      "step 12700 | train loss 0.1923\n",
      "step 12720 | train loss 0.1899\n",
      "step 12740 | train loss 0.1958\n",
      "step 12760 | train loss 0.1994\n",
      "step 12780 | train loss 0.1913\n",
      "step 12800 | train loss 0.1974\n",
      "*** eval step 12800: val loss 4.8189\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of courage, sir; let him need award:\n",
      "He's not past stant come. Farewelling tears;\n",
      "For their harms and sa\n",
      "step 12820 | train loss 0.1931\n",
      "step 12840 | train loss 0.1859\n",
      "step 12860 | train loss 0.1933\n",
      "step 12880 | train loss 0.1908\n",
      "step 12900 | train loss 0.1957\n",
      "step 12920 | train loss 0.1879\n",
      "step 12940 | train loss 0.1901\n",
      "step 12960 | train loss 0.1949\n",
      "step 12980 | train loss 0.1878\n",
      "step 13000 | train loss 0.1945\n",
      "*** eval step 13000: val loss 4.8239\n",
      "SAMPLE: First Citizen:\n",
      "Before thy other Escalus, whose both are those wholesome homeals accused heart\n",
      "To combine hear, not so neithing, nor a me\n",
      "step 13020 | train loss 0.1909\n",
      "step 13040 | train loss 0.1957\n",
      "step 13060 | train loss 0.1891\n",
      "step 13080 | train loss 0.1934\n",
      "step 13100 | train loss 0.1930\n",
      "step 13120 | train loss 0.1884\n",
      "step 13140 | train loss 0.1897\n",
      "step 13160 | train loss 0.1958\n",
      "step 13180 | train loss 0.1903\n",
      "step 13200 | train loss 0.1924\n",
      "*** eval step 13200: val loss 4.8321\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r lady; seldom comes the better:\n",
      "I fear, I fear 'twill prove a troublous world.\n",
      "\n",
      "Third Citizen:\n",
      "Neighbours, \n",
      "step 13220 | train loss 0.1814\n",
      "step 13240 | train loss 0.1859\n",
      "step 13260 | train loss 0.1888\n",
      "step 13280 | train loss 0.1854\n",
      "step 13300 | train loss 0.1885\n",
      "step 13320 | train loss 0.1882\n",
      "step 13340 | train loss 0.1892\n",
      "step 13360 | train loss 0.1909\n",
      "step 13380 | train loss 0.1918\n",
      "step 13400 | train loss 0.1891\n",
      "*** eval step 13400: val loss 4.8762\n",
      "SAMPLE: First Citizen:\n",
      "Both and howlloes and lewary cozened but as surfeit.\n",
      "Or, if she be slain; the she doth off.\n",
      "\n",
      "Nurse:\n",
      "O women, a thing mann\n",
      "step 13420 | train loss 0.1871\n",
      "step 13440 | train loss 0.1920\n",
      "step 13460 | train loss 0.1912\n",
      "step 13480 | train loss 0.1873\n",
      "step 13500 | train loss 0.1942\n",
      "step 13520 | train loss 0.1950\n",
      "step 13540 | train loss 0.1903\n",
      "step 13560 | train loss 0.1927\n",
      "step 13580 | train loss 0.1835\n",
      "step 13600 | train loss 0.1857\n",
      "*** eval step 13600: val loss 4.8745\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they all came by the father,\n",
      "Or by the father there were none at all;\n",
      "For emulation now, who shall be frie\n",
      "step 13620 | train loss 0.1874\n",
      "step 13640 | train loss 0.1905\n",
      "step 13660 | train loss 0.1891\n",
      "step 13680 | train loss 0.1865\n",
      "step 13700 | train loss 0.1899\n",
      "step 13720 | train loss 0.1875\n",
      "step 13740 | train loss 0.1897\n",
      "step 13760 | train loss 0.1867\n",
      "step 13780 | train loss 0.1887\n",
      "step 13800 | train loss 0.1874\n",
      "*** eval step 13800: val loss 4.9286\n",
      "SAMPLE: First Citizen:\n",
      "Believe me, sole it, in possible coals!\n",
      "\n",
      "BENVOLIO:\n",
      "O no more deviled, have you told him of your time.\n",
      "\n",
      "ROMEO:\n",
      "And breathe\n",
      "step 13820 | train loss 0.1854\n",
      "step 13840 | train loss 0.1911\n",
      "step 13860 | train loss 0.1893\n",
      "step 13880 | train loss 0.1893\n",
      "step 13900 | train loss 0.1844\n",
      "step 13920 | train loss 0.1910\n",
      "step 13940 | train loss 0.1868\n",
      "step 13960 | train loss 0.1884\n",
      "step 13980 | train loss 0.1874\n",
      "step 14000 | train loss 0.1841\n",
      "*** eval step 14000: val loss 4.9047\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they all came by the father,\n",
      "Or by the father there were none at all;\n",
      "For emulation now, who shall be near\n",
      "step 14020 | train loss 0.1902\n",
      "step 14040 | train loss 0.1852\n",
      "step 14060 | train loss 0.1857\n",
      "step 14080 | train loss 0.1903\n",
      "step 14100 | train loss 0.1887\n",
      "step 14120 | train loss 0.1890\n",
      "step 14140 | train loss 0.1861\n",
      "step 14160 | train loss 0.1807\n",
      "step 14180 | train loss 0.1882\n",
      "step 14200 | train loss 0.1855\n",
      "*** eval step 14200: val loss 4.9343\n",
      "SAMPLE: First Citizen:\n",
      "Bad news; but how came to my brother: If any thing but\n",
      "gettle, nor what they do so well by: both which does the\n",
      "divideu: \n",
      "step 14220 | train loss 0.1867\n",
      "step 14240 | train loss 0.1901\n",
      "step 14260 | train loss 0.1844\n",
      "step 14280 | train loss 0.1870\n",
      "step 14300 | train loss 0.1897\n",
      "step 14320 | train loss 0.1822\n",
      "step 14340 | train loss 0.1816\n",
      "step 14360 | train loss 0.1902\n",
      "step 14380 | train loss 0.1863\n",
      "step 14400 | train loss 0.1843\n",
      "*** eval step 14400: val loss 4.9706\n",
      "SAMPLE: First Citizen:\n",
      "Better it were a kind of all incensed o' the queenneineds.\n",
      "Go, poor gracious sovereign, hide person and\n",
      "loves not the com\n",
      "step 14420 | train loss 0.1799\n",
      "step 14440 | train loss 0.1869\n",
      "step 14460 | train loss 0.1920\n",
      "step 14480 | train loss 0.1850\n",
      "step 14500 | train loss 0.1877\n",
      "step 14520 | train loss 0.1850\n",
      "step 14540 | train loss 0.1853\n",
      "step 14560 | train loss 0.1874\n",
      "step 14580 | train loss 0.1829\n",
      "step 14600 | train loss 0.1892\n",
      "*** eval step 14600: val loss 4.9842\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instinct men's minds missor to my wife.\n",
      "The commons up this shame\n",
      "step 14620 | train loss 0.1793\n",
      "step 14640 | train loss 0.1848\n",
      "step 14660 | train loss 0.1825\n",
      "step 14680 | train loss 0.1835\n",
      "step 14700 | train loss 0.1823\n",
      "step 14720 | train loss 0.1804\n",
      "step 14740 | train loss 0.1815\n",
      "step 14760 | train loss 0.1775\n",
      "step 14780 | train loss 0.1845\n",
      "step 14800 | train loss 0.1823\n",
      "*** eval step 14800: val loss 4.9692\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r light on no strict that reproofs.\n",
      "\n",
      "CAPULET:\n",
      "Why, I am glad on't; this is well: stand up:\n",
      "This is as't shou\n",
      "step 14820 | train loss 0.1796\n",
      "step 14840 | train loss 0.1871\n",
      "step 14860 | train loss 0.1811\n",
      "step 14880 | train loss 0.1834\n",
      "step 14900 | train loss 0.1847\n",
      "step 14920 | train loss 0.1823\n",
      "step 14940 | train loss 0.1797\n",
      "step 14960 | train loss 0.1847\n",
      "step 14980 | train loss 0.1853\n",
      "step 15000 | train loss 0.1798\n",
      "*** eval step 15000: val loss 5.0118\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r lady; seldom coming.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Madam, good hope; his grace speaks cheerfully.\n",
      "\n",
      "QUEEN:\n",
      "God gild some poi\n",
      "step 15020 | train loss 0.1810\n",
      "step 15040 | train loss 0.1803\n",
      "step 15060 | train loss 0.1875\n",
      "step 15080 | train loss 0.1829\n",
      "step 15100 | train loss 0.1804\n",
      "step 15120 | train loss 0.1818\n",
      "step 15140 | train loss 0.1825\n",
      "step 15160 | train loss 0.1781\n",
      "step 15180 | train loss 0.1825\n",
      "step 15200 | train loss 0.1826\n",
      "*** eval step 15200: val loss 5.0459\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instinct men's minds mistrust\n",
      "Ensuither accuseth for a cause;\n",
      "But\n",
      "step 15220 | train loss 0.1827\n",
      "step 15240 | train loss 0.1775\n",
      "step 15260 | train loss 0.1823\n",
      "step 15280 | train loss 0.1847\n",
      "step 15300 | train loss 0.1830\n",
      "step 15320 | train loss 0.1829\n",
      "step 15340 | train loss 0.1854\n",
      "step 15360 | train loss 0.1853\n",
      "step 15380 | train loss 0.1831\n",
      "step 15400 | train loss 0.1818\n",
      "*** eval step 15400: val loss 5.0569\n",
      "SAMPLE: First Citizen:\n",
      "Bad night as Bolingbroke doth quiet with this as beard.\n",
      "\n",
      "SICINIUS:\n",
      "Pray you, go to him.\n",
      "\n",
      "MENENIUS:\n",
      "What should I do?\n",
      "\n",
      "BRU\n",
      "step 15420 | train loss 0.1823\n",
      "step 15440 | train loss 0.1820\n",
      "step 15460 | train loss 0.1790\n",
      "step 15480 | train loss 0.1823\n",
      "step 15500 | train loss 0.1810\n",
      "step 15520 | train loss 0.1788\n",
      "step 15540 | train loss 0.1788\n",
      "step 15560 | train loss 0.1849\n",
      "step 15580 | train loss 0.1810\n",
      "step 15600 | train loss 0.1828\n",
      "*** eval step 15600: val loss 5.0722\n",
      "SAMPLE: First Citizen:\n",
      "Between the child by tropp'd her he has clush'd and thy root piece,\n",
      "Which, I presume, he'll take in gentle part.\n",
      "\n",
      "BISHOP \n",
      "step 15620 | train loss 0.1789\n",
      "step 15640 | train loss 0.1803\n",
      "step 15660 | train loss 0.1817\n",
      "step 15680 | train loss 0.1808\n",
      "step 15700 | train loss 0.1773\n",
      "step 15720 | train loss 0.1773\n",
      "step 15740 | train loss 0.1775\n",
      "step 15760 | train loss 0.1720\n",
      "step 15780 | train loss 0.1803\n",
      "step 15800 | train loss 0.1772\n",
      "*** eval step 15800: val loss 5.0570\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r lady; seldom comes the breath of words\n",
      "Intend to accompanied me what art we have dispair?\n",
      "\n",
      "JULIET:\n",
      "The chi\n",
      "step 15820 | train loss 0.1770\n",
      "step 15840 | train loss 0.1761\n",
      "step 15860 | train loss 0.1799\n",
      "step 15880 | train loss 0.1777\n",
      "step 15900 | train loss 0.1800\n",
      "step 15920 | train loss 0.1784\n",
      "step 15940 | train loss 0.1769\n",
      "step 15960 | train loss 0.1755\n",
      "step 15980 | train loss 0.1785\n",
      "step 16000 | train loss 0.1765\n",
      "*** eval step 16000: val loss 5.1113\n",
      "SAMPLE: First Citizen:\n",
      "By say your for your voices and blood, your father's life\n",
      "Hath winded love Lammarquey. Her\n",
      "shall my lovok'd on and humble\n",
      "step 16020 | train loss 0.1750\n",
      "step 16040 | train loss 0.1799\n",
      "step 16060 | train loss 0.1781\n",
      "step 16080 | train loss 0.1780\n",
      "step 16100 | train loss 0.1759\n",
      "step 16120 | train loss 0.1761\n",
      "step 16140 | train loss 0.1801\n",
      "step 16160 | train loss 0.1763\n",
      "step 16180 | train loss 0.1793\n",
      "step 16200 | train loss 0.1736\n",
      "*** eval step 16200: val loss 5.0975\n",
      "SAMPLE: First Citizen:\n",
      "Bad me to wand; I will stand the king and forth\n",
      "Divost again creation, and the eyes of the world.\n",
      "\n",
      "AUTOLYCUS:\n",
      "Beseech you\n",
      "step 16220 | train loss 0.1811\n",
      "step 16240 | train loss 0.1753\n",
      "step 16260 | train loss 0.1763\n",
      "step 16280 | train loss 0.1776\n",
      "step 16300 | train loss 0.1806\n",
      "step 16320 | train loss 0.1809\n",
      "step 16340 | train loss 0.1801\n",
      "step 16360 | train loss 0.1744\n",
      "step 16380 | train loss 0.1763\n",
      "step 16400 | train loss 0.1797\n",
      "*** eval step 16400: val loss 5.0616\n",
      "SAMPLE: First Citizen:\n",
      "Better it were they aband could be content the is\n",
      "Were swell a black, that dog it gone; if not, how have :\n",
      "My words ackno\n",
      "step 16420 | train loss 0.1831\n",
      "step 16440 | train loss 0.1760\n",
      "step 16460 | train loss 0.1811\n",
      "step 16480 | train loss 0.1776\n",
      "step 16500 | train loss 0.1798\n",
      "step 16520 | train loss 0.1759\n",
      "step 16540 | train loss 0.1751\n",
      "step 16560 | train loss 0.1743\n",
      "step 16580 | train loss 0.1821\n",
      "step 16600 | train loss 0.1745\n",
      "*** eval step 16600: val loss 5.1160\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of know rich and discation\n",
      "May enter ough.\n",
      "\n",
      "AUTOLYCUS:\n",
      "I mourns may, my lord, give me the streets of you\n",
      "step 16620 | train loss 0.1753\n",
      "step 16640 | train loss 0.1828\n",
      "step 16660 | train loss 0.1788\n",
      "step 16680 | train loss 0.1766\n",
      "step 16700 | train loss 0.1758\n",
      "step 16720 | train loss 0.1741\n",
      "step 16740 | train loss 0.1721\n",
      "step 16760 | train loss 0.1772\n",
      "step 16780 | train loss 0.1784\n",
      "step 16800 | train loss 0.1778\n",
      "*** eval step 16800: val loss 5.1259\n",
      "SAMPLE: First Citizen:\n",
      "Befall thee so bride me none: let him kind a\n",
      "bord. His learning my remembrance my dr\n",
      "danger cries and new suffer in the t\n",
      "step 16820 | train loss 0.1793\n",
      "step 16840 | train loss 0.1829\n",
      "step 16860 | train loss 0.1826\n",
      "step 16880 | train loss 0.1761\n",
      "step 16900 | train loss 0.1708\n",
      "step 16920 | train loss 0.1718\n",
      "step 16940 | train loss 0.1806\n",
      "step 16960 | train loss 0.1756\n",
      "step 16980 | train loss 0.1802\n",
      "step 17000 | train loss 0.1760\n",
      "*** eval step 17000: val loss 5.1533\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "Behing it his intelligence that you command,\n",
      "Which the dise passent you to at\n",
      "step 17020 | train loss 0.1780\n",
      "step 17040 | train loss 0.1772\n",
      "step 17060 | train loss 0.1693\n",
      "step 17080 | train loss 0.1718\n",
      "step 17100 | train loss 0.1728\n",
      "step 17120 | train loss 0.1779\n",
      "step 17140 | train loss 0.1765\n",
      "step 17160 | train loss 0.1769\n",
      "step 17180 | train loss 0.1765\n",
      "step 17200 | train loss 0.1715\n",
      "*** eval step 17200: val loss 5.1083\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instinct men's minds mistrust\n",
      "Ensuing dangers; as by my love both\n",
      "step 17220 | train loss 0.1720\n",
      "step 17240 | train loss 0.1735\n",
      "step 17260 | train loss 0.1767\n",
      "step 17280 | train loss 0.1749\n",
      "step 17300 | train loss 0.1785\n",
      "step 17320 | train loss 0.1723\n",
      "step 17340 | train loss 0.1760\n",
      "step 17360 | train loss 0.1717\n",
      "step 17380 | train loss 0.1693\n",
      "step 17400 | train loss 0.1717\n",
      "*** eval step 17400: val loss 5.1873\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r lady; seldom comes the better:\n",
      "I fear, I fear 'twill prove a tyrant;\n",
      "But if he be accused it would be thus\n",
      "step 17420 | train loss 0.1748\n",
      "step 17440 | train loss 0.1700\n",
      "step 17460 | train loss 0.1761\n",
      "step 17480 | train loss 0.1715\n",
      "step 17500 | train loss 0.1730\n",
      "step 17520 | train loss 0.1736\n",
      "step 17540 | train loss 0.1736\n",
      "step 17560 | train loss 0.1718\n",
      "step 17580 | train loss 0.1749\n",
      "step 17600 | train loss 0.1723\n",
      "*** eval step 17600: val loss 5.1601\n",
      "SAMPLE: First Citizen:\n",
      "Better of content and her affection,\n",
      "Her body of a great creatural\n",
      "Such feelious sing; the loss o' thy resolved\n",
      "First, he\n",
      "step 17620 | train loss 0.1744\n",
      "step 17640 | train loss 0.1713\n",
      "step 17660 | train loss 0.1722\n",
      "step 17680 | train loss 0.1758\n",
      "step 17700 | train loss 0.1701\n",
      "step 17720 | train loss 0.1733\n",
      "step 17740 | train loss 0.1702\n",
      "step 17760 | train loss 0.1732\n",
      "step 17780 | train loss 0.1686\n",
      "step 17800 | train loss 0.1753\n",
      "*** eval step 17800: val loss 5.2232\n",
      "SAMPLE: First Citizen:\n",
      "Became the tyrants lips?\n",
      "\n",
      "MERCUTIO:\n",
      "Men old her count and fair voice of are traitors\n",
      "And make us lose the gates of York,\n",
      "\n",
      "step 17820 | train loss 0.1734\n",
      "step 17840 | train loss 0.1715\n",
      "step 17860 | train loss 0.1728\n",
      "step 17880 | train loss 0.1699\n",
      "step 17900 | train loss 0.1718\n",
      "step 17920 | train loss 0.1712\n",
      "step 17940 | train loss 0.1760\n",
      "step 17960 | train loss 0.1749\n",
      "step 17980 | train loss 0.1789\n",
      "step 18000 | train loss 0.1743\n",
      "*** eval step 18000: val loss 5.2462\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instinct men's minds mistrust\n",
      "Ensuing dangers; as by proof, we se\n",
      "step 18020 | train loss 0.1722\n",
      "step 18040 | train loss 0.1694\n",
      "step 18060 | train loss 0.1739\n",
      "step 18080 | train loss 0.1786\n",
      "step 18100 | train loss 0.1719\n",
      "step 18120 | train loss 0.1712\n",
      "step 18140 | train loss 0.1737\n",
      "step 18160 | train loss 0.1758\n",
      "step 18180 | train loss 0.1717\n",
      "step 18200 | train loss 0.1708\n",
      "*** eval step 18200: val loss 5.2077\n",
      "SAMPLE: First Citizen:\n",
      "Befheir the tide of Romeo for ever.\n",
      "\n",
      "LUCIO:\n",
      "But you man's good fool: 'A I despist\n",
      "I wised of such a cousin, need weeps\n",
      "Ti\n",
      "step 18220 | train loss 0.1672\n",
      "step 18240 | train loss 0.1729\n",
      "step 18260 | train loss 0.1693\n",
      "step 18280 | train loss 0.1718\n",
      "step 18300 | train loss 0.1681\n",
      "step 18320 | train loss 0.1709\n",
      "step 18340 | train loss 0.1725\n",
      "step 18360 | train loss 0.1705\n",
      "step 18380 | train loss 0.1710\n",
      "step 18400 | train loss 0.1712\n",
      "*** eval step 18400: val loss 5.2635\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divine instinct men's minds mistrust\n",
      "Ensuing dangers; as by proof, we se\n",
      "step 18420 | train loss 0.1684\n",
      "step 18440 | train loss 0.1708\n",
      "step 18460 | train loss 0.1697\n",
      "step 18480 | train loss 0.1724\n",
      "step 18500 | train loss 0.1778\n",
      "step 18520 | train loss 0.1679\n",
      "step 18540 | train loss 0.1711\n",
      "step 18560 | train loss 0.1693\n",
      "step 18580 | train loss 0.1669\n",
      "step 18600 | train loss 0.1686\n",
      "*** eval step 18600: val loss 5.2506\n",
      "SAMPLE: First Citizen:\n",
      "Bad night, for she shall at Barnet pains:\n",
      "And, to stabbed with G, to hell hear for this can made?\n",
      "\n",
      "KING RICHARD II:\n",
      "Your \n",
      "step 18620 | train loss 0.1656\n",
      "step 18640 | train loss 0.1749\n",
      "step 18660 | train loss 0.1709\n",
      "step 18680 | train loss 0.1691\n",
      "step 18700 | train loss 0.1702\n",
      "step 18720 | train loss 0.1710\n",
      "step 18740 | train loss 0.1670\n",
      "step 18760 | train loss 0.1680\n",
      "step 18780 | train loss 0.1734\n",
      "step 18800 | train loss 0.1632\n",
      "*** eval step 18800: val loss 5.2541\n",
      "SAMPLE: First Citizen:\n",
      "Before the times of change, still is it so:\n",
      "By a divinest it is too noble for him:\n",
      "Do yorset, sir, hold your heart; but m\n",
      "step 18820 | train loss 0.1664\n",
      "step 18840 | train loss 0.1741\n",
      "step 18860 | train loss 0.1687\n",
      "step 18880 | train loss 0.1702\n",
      "step 18900 | train loss 0.1728\n",
      "step 18920 | train loss 0.1641\n",
      "step 18940 | train loss 0.1678\n",
      "step 18960 | train loss 0.1696\n",
      "step 18980 | train loss 0.1695\n",
      "step 19000 | train loss 0.1649\n",
      "*** eval step 19000: val loss 5.2548\n",
      "SAMPLE: First Citizen:\n",
      "Bid she so. But Tribunes' know thou hast, whether thou art\n",
      "not thy good counsel me curs; and what your grace's worse,\n",
      "Tha\n",
      "step 19020 | train loss 0.1704\n",
      "step 19040 | train loss 0.1683\n",
      "step 19060 | train loss 0.1715\n",
      "step 19080 | train loss 0.1712\n",
      "step 19100 | train loss 0.1713\n",
      "step 19120 | train loss 0.1745\n",
      "step 19140 | train loss 0.1702\n",
      "step 19160 | train loss 0.1707\n",
      "step 19180 | train loss 0.1699\n",
      "step 19200 | train loss 0.1710\n",
      "*** eval step 19200: val loss 5.2801\n",
      "SAMPLE: First Citizen:\n",
      "Before the gods do I leave you.\n",
      "\n",
      "SICINIUS:\n",
      "Wrath-bring to blow their spoils, may still their spears to the\n",
      "his house of a\n",
      "step 19220 | train loss 0.1689\n",
      "step 19240 | train loss 0.1698\n",
      "step 19260 | train loss 0.1712\n",
      "step 19280 | train loss 0.1681\n",
      "step 19300 | train loss 0.1666\n",
      "step 19320 | train loss 0.1671\n",
      "step 19340 | train loss 0.1701\n",
      "step 19360 | train loss 0.1690\n",
      "step 19380 | train loss 0.1648\n",
      "step 19400 | train loss 0.1681\n",
      "*** eval step 19400: val loss 5.2535\n",
      "SAMPLE: First Citizen:\n",
      "Before thy two wears and safely reverence.\n",
      "Now, Thus far is thy hands thus can see\n",
      "Thy bids bewing them to the light.\n",
      "\n",
      "Fi\n",
      "step 19420 | train loss 0.1687\n",
      "step 19440 | train loss 0.1727\n",
      "step 19460 | train loss 0.1689\n",
      "step 19480 | train loss 0.1678\n",
      "step 19500 | train loss 0.1704\n",
      "step 19520 | train loss 0.1699\n",
      "step 19540 | train loss 0.1732\n",
      "step 19560 | train loss 0.1697\n",
      "step 19580 | train loss 0.1681\n",
      "step 19600 | train loss 0.1660\n",
      "*** eval step 19600: val loss 5.2736\n",
      "SAMPLE: First Citizen:\n",
      "Bad news, by'r lady; seldom comes the better:\n",
      "I fear, I fear 'twill prove a troublous world.\n",
      "\n",
      "Third Citizen:\n",
      "Neighbours, \n",
      "step 19620 | train loss 0.1637\n",
      "step 19640 | train loss 0.1610\n",
      "step 19660 | train loss 0.1656\n",
      "step 19680 | train loss 0.1692\n",
      "step 19700 | train loss 0.1636\n",
      "step 19720 | train loss 0.1648\n",
      "step 19740 | train loss 0.1688\n",
      "step 19760 | train loss 0.1633\n",
      "step 19780 | train loss 0.1646\n",
      "step 19800 | train loss 0.1631\n",
      "*** eval step 19800: val loss 5.2936\n",
      "SAMPLE: First Citizen:\n",
      "Before the tide occasion of knighthood violency\n",
      "From the dead temples of this bloody wretch\n",
      "Have I pluck'd off, to grace \n",
      "step 19820 | train loss 0.1674\n",
      "step 19840 | train loss 0.1660\n",
      "step 19860 | train loss 0.1675\n",
      "step 19880 | train loss 0.1640\n",
      "step 19900 | train loss 0.1660\n",
      "step 19920 | train loss 0.1671\n",
      "step 19940 | train loss 0.1689\n",
      "step 19960 | train loss 0.1659\n",
      "step 19980 | train loss 0.1682\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "train_ids, val_ids = load_data(DATA_PATH)\n",
    "train_ds = TokenDataset(train_ids, context_length)\n",
    "val_ds   = TokenDataset(val_ids, context_length)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "model = SmallLanguageModel().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "step = 0\n",
    "best = float(\"inf\")\n",
    "while step < max_steps:\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"step {step:5d} | train loss {loss.item():.4f}\")\n",
    "\n",
    "        if step % eval_interval == 0:\n",
    "            v = estimate_loss(model, val_loader)\n",
    "            print(f\"*** eval step {step}: val loss {v:.4f}\")\n",
    "            if v < best:\n",
    "                best = v\n",
    "                torch.save(model.state_dict(), \"best_small_lm_like.pt\")\n",
    "                print(\"saved best_small_lm_like.pt\")\n",
    "            # quick sample\n",
    "            ctx = torch.tensor([train_ids[:min(16, len(train_ids))]], dtype=torch.long, device=device)\n",
    "            out = generate(model, ctx, max_new_tokens=120, temperature=0.9, top_k=50)[0].tolist()\n",
    "            print(\"SAMPLE:\", tokenizer.decode(out))\n",
    "        step += 1\n",
    "        if step >= max_steps: break\n",
    "\n",
    "torch.save(model.state_dict(), \"final_small_lm_like.pt\")\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf154fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt: str, model_path=\"best_small_lm_like.pt\", max_new_tokens=100, temperature=0.8, top_k=50):\n",
    "    # load tokenizer (same as training)\n",
    "    tokenizer = ByteTokenizer()\n",
    "\n",
    "    # init model and load weights\n",
    "    model = SmallLanguageModel().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # encode prompt into tokens\n",
    "    start_ids = tokenizer.encode(prompt)\n",
    "    x = torch.tensor([start_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # generate\n",
    "    out = generate(model, x, max_new_tokens=max_new_tokens,\n",
    "                   temperature=temperature, top_k=top_k)\n",
    "\n",
    "    # decode to string\n",
    "    result = tokenizer.decode(out[0].tolist())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db93955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, madam, I may be them go.\\n\\nBUCKINGHAM:\\nCome on! And for comes there, now of thy beautificate,\\nFor s'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(\"Once upon a time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
