{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoders\n",
    "Main Problem on this are Alighment methods of Many2Many models.\n",
    "\n",
    "■ If we want an output with a different length from the input (e.g. Machine Translation),\n",
    "what should we do?\n",
    "\n",
    "■ Which alignment method should we use?\n",
    "\n",
    "\n",
    "Solution is a encoder-decoder architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/Encoder-Decoders.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ Encoder: The encoder processes the input sequence and compresses the information\n",
    "into a fixed length vector, known as the context vector.\n",
    "\n",
    "■ Context Vector (Hidden State): This vector is expected to convey the meaning of the\n",
    "whole source sequence from the encoder to the decoder.\n",
    "▶ The early work considered the last state of the encoder network as the\n",
    "context vector.\n",
    "\n",
    "■ Decoder: The decoder uses the context vector to output the desired target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "■ The context vector is bottleneck . By increasing the length of the input sequence, the\n",
    "model captures the essential information roughly (Vanishing still exists). How to solve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Forcing\n",
    "we calculate an extra loss at time of passing the output to next block also at next word prediction.\n",
    "\n",
    "■ Teacher forcing is a method for training recurrent neural networks more efficiently.\n",
    "\n",
    "■ Teacher forcing works by using the actual output at the current time step y\n",
    "(t−1) as input\n",
    "in the next time step, rather than the o\n",
    "(t−1)generated by the network.\n",
    "\n",
    "■ At the early stages of training, the predictions of the model are very bad.\n",
    "\n",
    "■ If we do not use Teacher Forcing, the hidden states of the model will be updated by a\n",
    "sequence of wrong predictions, errors will accumulate.\n",
    "\n",
    "■ It will be difficult for the model to learn from that.\n",
    "\n",
    "■ This technique allows us to prevent backpropagation through time which was complex\n",
    "and time­consuming. With teacher forcing the model will be trained faster ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Startegy\n",
    "\n",
    "How we should select best words, considering we cannot brute force casue vocab size is too large. O(V^T)\n",
    "\n",
    "greedy can also be used but it can be very in accurate O(V.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search\n",
    "Greedy algorithm with k candidates, O(log(k).k.V.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sampling\n",
    "a way of optimiztion on one part of our formulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
